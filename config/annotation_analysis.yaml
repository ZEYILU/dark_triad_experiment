# Annotation Analysis Configuration
# Configuration for multi-annotator agreement analysis

paths:
  base_dir: "."
  annotator_pattern: "annotator*_llm_validation_samples_stratified_*.csv"
  ground_truth_pattern: "llm_validation_samples_stratified_*_ground_truth.csv"
  ground_truth_fallback: "annotation_ground_truth.csv"
  output_dir: "results/multi_annotator_analysis"

analysis:
  categories:
    - REFUSAL
    - REINFORCING
    - CORRECTIVE
    - MIXED

  # Fleiss' Kappa interpretation thresholds (Landis & Koch, 1977)
  kappa_thresholds:
    poor: 0.0
    slight: 0.20
    fair: 0.40
    moderate: 0.60
    substantial: 0.80
    almost_perfect: 1.00

  # Code to label mapping
  code_to_label:
    1: "REFUSAL"
    2: "REINFORCING"
    3: "CORRECTIVE"
    4: "MIXED"

visualization:
  dpi: 300
  figsize: [12, 8]
  confusion_matrix_figsize: [10, 8]
  per_category_figsize: [12, 7]

  # Color palette for visualizations
  colors:
    - "#2E86AB"  # Blue
    - "#A23B72"  # Purple
    - "#F18F01"  # Orange
    - "#C73E1D"  # Red
    - "#6A994E"  # Green

  # Colormap for heatmaps
  cmap: "Blues"

  # Font sizes
  title_fontsize: 14
  label_fontsize: 12
  tick_fontsize: 11
  annotation_fontsize: 8

output:
  # File naming conventions
  confusion_matrix_prefix: "confusion_matrix_"
  per_category_chart: "per_category_agreement.png"
  per_category_csv: "per_category_agreement.csv"
  disagreements_csv: "disagreements_detailed.csv"
  pairwise_csv: "pairwise_agreement.csv"
  annotator_vs_llm_csv: "annotator_vs_llm_agreement.csv"
  agreement_report: "inter_annotator_agreement_report.txt"
  merged_data: "merged_annotations.csv"

  # Encoding for CSV files
  csv_encoding: "utf-8-sig"
